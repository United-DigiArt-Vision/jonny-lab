# OpenAI CA Law Violation ‚Äî GPT-5.3-Codex

**Date:** 2026-02-10
**Topic:** OpenAI violates California AI Safety Law (SB 53) with GPT-5.3-Codex release
**Source:** Fortune, Midas Project, CA SB 53
**Score:** 9/10
**Account:** @DaBrusi

---

## Thread Content

**1/10**
üö® BREAKING: OpenAI appears to have violated California's AI safety law with its GPT-5.3-Codex release, according to watchdog group The Midas Project.

This could trigger millions in fines ‚Äî and set a precedent for AI regulation enforcement.

Here's what happened üëá

---

**2/10**
The facts:

‚Ä¢ GPT-5.3-Codex: OpenAI's newest coding model
‚Ä¢ First to hit "HIGH" cybersecurity risk on OpenAI's own framework
‚Ä¢ CA SB 53: Requires companies to stick to their own safety plans (effective Jan 2026)
‚Ä¢ Penalty: Millions in fines for violations

The problem? OpenAI didn't follow its own rules.

---

**3/10**
What is GPT-5.3-Codex?

It's OpenAI's newest coding model ‚Äî part of an effort to reclaim its lead in AI-powered coding.

According to benchmarks, it outperforms all earlier models from OpenAI and competitors like Anthropic.

But it's also the first model to hit OpenAI's "HIGH" cybersecurity risk category.

---

**4/10**
What is CA SB 53?

California's landmark AI safety law (effective Jan 2026) requires major AI companies to:

‚Ä¢ Publish their own safety frameworks
‚Ä¢ Stick to them
‚Ä¢ Prevent catastrophic risks ($1B+ damage OR 50+ deaths)
‚Ä¢ Not make misleading statements about compliance

OpenAI's own framework = now legally binding.

---

**5/10**
The problem:

OpenAI's framework requires SPECIAL SAFEGUARDS for models with HIGH cyber risk ‚Äî designed to prevent:

‚Ä¢ Deceptive behavior
‚Ä¢ Sabotage of safety research
‚Ä¢ Hiding true capabilities

OpenAI did NOT implement these safeguards before launching GPT-5.3-Codex.

---

**CTA (no number)**
If you're enjoying this breakdown, follow @DaBrusi for daily tech & innovation threads!

A like or repost helps more than you think üôè

---

**6/10**
The watchdog's claim:

Midas Project says OpenAI cannot definitively prove GPT-5.3-Codex lacks the "long-range autonomy" required for safeguards.

Why? OpenAI's PREVIOUS, less advanced model already topped global benchmarks for autonomous task completion.

Even if the rules were unclear, they should've been clarified BEFORE release.

---

**7/10**
OpenAI's defense:

The company claims the framework wording is "ambiguous."

Safeguards are only needed when HIGH cyber risk occurs "in conjunction with" long-range autonomy (ability to operate independently over time).

Since they believe GPT-5.3-Codex lacks this autonomy ‚Üí no safeguards needed.

OpenAI says they're "confident in compliance."

---

**8/10**
But safety researchers disagree.

Nathan Calvin (VP at Encode):
"Rather than admit they didn't follow their plan, OpenAI is saying the criteria was ambiguous. From reading the docs‚Ä¶ it doesn't look ambiguous to me."

Tyler Johnston (Midas Project founder):
"Especially embarrassing given how low the floor SB 53 sets: basically just adopt a voluntary safety plan and communicate honestly about it."

---

**9/10**
What's at stake?

‚Ä¢ If allegations prove accurate: Millions in fines
‚Ä¢ First major test of CA SB 53 enforcement
‚Ä¢ Precedent for AI regulation in the USA
‚Ä¢ Signal to other states considering similar laws

CA Attorney General's Office: "Committed to enforcing the laws of our state, including those enacted to increase transparency and safety in the emerging AI space."

---

**10/10**
The bigger picture:

AI safety vs. speed.

OpenAI is racing to reclaim its lead in coding AI ‚Äî but California's law is forcing companies to choose: move fast, or comply.

This case will define whether "voluntary" safety frameworks backed by law have real teeth.

Watch this space. üöÄ

---

## Post-Thread Notes

**Reply-Jack Targets:**
- [ ] @sama (Sam Altman) ‚Äî if he tweets about GPT-5.3-Codex
- [ ] @OpenAI ‚Äî official announcements
- [ ] @AnthropicAI ‚Äî competitor angle
- [ ] Large accounts discussing AI safety / regulation

**Monetization Angle:**
AI compliance consulting, safety auditing services, regulatory guidance for AI companies navigating SB 53 and similar laws.

**Follow-Up:**
- CA AG investigation announcement?
- OpenAI framework clarification?
- Other companies facing similar scrutiny?
